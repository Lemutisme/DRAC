# @package _global_

# Default configuration for d3rl algorithm
defaults:
  - _self_
  - env/d3rl: pendulum
  - env_mods  # New include for environment modifications
  - override hydra/job_logging: default
  - override hydra/hydra_logging: default

# General settings
device: cuda
mode: offline # offline, continual, generate
model: TD3 # TD3, SAC, DDPG
write: false
debug_print: false
render: false
load_model: false
load_path: None
eval_model: false
save_model: true
data_path: None

# Generating settings(epsilon-greedy)
epsilon: 0.1

# Training settings
seed: 42
max_train_steps: 200000
save_interval: 10000
eval_interval: 1000
update_every: 50
learning_starts: 10000

# Algorithm hyperparameters
gamma: 0.99
tau: 0.005
net_arch: [256,256]
net_layer: 1
n_critic: 2
a_lr: 0.0003 
c_lr: 0.0003 
l2_reg: 0 # 1e-3
batch_size: 256 #256

# Environment configurations
reward_adapt: true
noise: false  # Legacy noise setting - consider using env_mods instead
type: gaussian
adv: false
spread: 0.0      # Legacy std setting - consider using env_mods instead
scale: 1.0    # Legacy scale setting - consider using env_mods instead
delta: 0.0

# Hydra output directory
hydra:
  run:
    dir: ./outputs/${model}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ./multirun/${model}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job:
    name: ${env_name}_training
    chdir: true  # Change to the output directory